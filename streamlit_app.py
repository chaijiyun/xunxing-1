import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import io
import os
from datetime import datetime, timedelta

# ==========================================
# å¯»æ˜Ÿé…ç½®åˆ†æç³»ç»Ÿ v7.2.0 (Decoupled Simulation)
# Author: å¯»æ˜Ÿæ¶æ„å¸ˆ
# Update Log:
#   v7.2.0: [New] é£é™©å®éªŒå®¤æ–°å¢â€œé‡‡æ ·çª—å£â€æ§åˆ¶ï¼Œè§£å†³çŸ­ä¹…æœŸèµ„äº§åœ¨é•¿å›æµ‹å‘¨æœŸä¸‹æŒ‡æ ‡è¢«ç¨€é‡Šçš„é—®é¢˜ã€‚
#   v7.1.4: [Fix] é¢‘ç‡è‡ªåŠ¨ä¾¦æµ‹ã€‚
# ==========================================

# ------------------------------------------
# 0. å…¨å±€å¸¸é‡ä¸é¢„è®¾ (Configuration)
# ------------------------------------------
CONFIG_FILE_PATH = "xunxing_config.pkl"

PRESET_MASTER_DEFAULT = [
    {'äº§å“åç§°': 'å›½å¯Œç‘åˆ1å·', 'ç­–ç•¥æ ‡ç­¾': 'ä¸»è§‚å¤šå¤´', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 16, 'å¼€æ”¾é¢‘ç‡': 'å‘¨åº¦', 'é”å®šæœŸ(æœˆ)': 3, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'åˆéª¥500å¯¹å†²AæœŸ', 'ç­–ç•¥æ ‡ç­¾': 'é‡åŒ–å¯¹å†²', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 20, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 3, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'åˆç»æœŸæƒå¥—åˆ©', 'ç­–ç•¥æ ‡ç­¾': 'æœŸæƒå¥—åˆ©', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 30, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 6, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'ç–é¹å®å›¾1å·', 'ç­–ç•¥æ ‡ç­¾': 'ä¸»è§‚å¤šå¤´', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 20, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 3, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'å¼€æ€æ²ªæ¸¯æ·±ä¼˜é€‰', 'ç­–ç•¥æ ‡ç­¾': 'ä¸»è§‚å¤šå¤´', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 17, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 1, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'å®½è¿œä¼˜åŠ¿æˆé•¿10å·', 'ç­–ç•¥æ ‡ç­¾': 'ä¸»è§‚å¤šå¤´', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 20, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 3, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'è“å¢¨é•¿æ²³1å·', 'ç­–ç•¥æ ‡ç­¾': 'ä¸»è§‚å¤šå¤´', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 20, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 1, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'å®æ³‰ç‰¹å®šç­–ç•¥1å·', 'ç­–ç•¥æ ‡ç­¾': 'ä¸»è§‚å¤šå¤´', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 15, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 12, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'å¹³æ–¹å’Œ1000æŒ‡æ•°å¢å¼º', 'ç­–ç•¥æ ‡ç­¾': 'é‡åŒ–æŒ‡å¢', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 16, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 3, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'å¹³æ–¹å’Œå¤šç­–ç•¥', 'ç­–ç•¥æ ‡ç­¾': 'å¤šç­–ç•¥', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 16, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 3, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'å¹³æ–¹å’Œé‡åŒ–é€‰è‚¡', 'ç­–ç•¥æ ‡ç­¾': 'é‡åŒ–é€‰è‚¡', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 16, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 3, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'å¹³æ–¹å’Œå¸‚åœºä¸­æ€§', 'ç­–ç•¥æ ‡ç­¾': 'é‡åŒ–å¯¹å†²', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 16, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 3, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'ç§¦å·1å·', 'ç­–ç•¥æ ‡ç­¾': 'ä¸»è§‚å¤šå¤´', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 15, 'å¼€æ”¾é¢‘ç‡': 'å‘¨åº¦', 'é”å®šæœŸ(æœˆ)': 3, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'ç¿éƒ¡èŠ‚èŠ‚é«˜11å·', 'ç­–ç•¥æ ‡ç­¾': 'ä¸»è§‚å¤šå¤´', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 20, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 6, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'å­åº¸1000æŒ‡å¢', 'ç­–ç•¥æ ‡ç­¾': 'é‡åŒ–æŒ‡å¢', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 20, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 12, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'å­åº¸500æŒ‡å¢', 'ç­–ç•¥æ ‡ç­¾': 'é‡åŒ–æŒ‡å¢', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 20, 'å¼€æ”¾é¢‘ç‡': 'æœˆåº¦', 'é”å®šæœŸ(æœˆ)': 12, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'å­åº¸ä¸­æ€§+cta', 'ç­–ç•¥æ ‡ç­¾': 'å¤šç­–ç•¥', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 20, 'å¼€æ”¾é¢‘ç‡': 'å‘¨åº¦', 'é”å®šæœŸ(æœˆ)': 12, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'å­åº¸ä¸­æ€§ç­–ç•¥', 'ç­–ç•¥æ ‡ç­¾': 'é‡åŒ–å¯¹å†²', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 20, 'å¼€æ”¾é¢‘ç‡': 'å‘¨åº¦', 'é”å®šæœŸ(æœˆ)': 12, 'èµå›æ•ˆç‡(T+n)': 4},
    {'äº§å“åç§°': 'å­åº¸é‡é€‰', 'ç­–ç•¥æ ‡ç­¾': 'é‡åŒ–é€‰è‚¡', 'å¹´ç®¡ç†è´¹(%)': 0, 'ä¸šç»©æŠ¥é…¬(%)': 20, 'å¼€æ”¾é¢‘ç‡': 'å‘¨åº¦', 'é”å®šæœŸ(æœˆ)': 12, 'èµå›æ•ˆç‡(T+n)': 4},
]
DEFAULT_MASTER_ROW = {"ç­–ç•¥æ ‡ç­¾": "æœªåˆ†ç±»", "å¹´ç®¡ç†è´¹(%)": 0.0, "ä¸šç»©æŠ¥é…¬(%)": 20.0, "å¼€æ”¾é¢‘ç‡": "æœˆåº¦", "é”å®šæœŸ(æœˆ)": 6, "èµå›æ•ˆç‡(T+n)": 5}

# ------------------------------------------
# 1. æŒä¹…åŒ–å¼•æ“ (Persistence Engine)
# ------------------------------------------
def load_local_config():
    if os.path.exists(CONFIG_FILE_PATH):
        try:
            df = pd.read_pickle(CONFIG_FILE_PATH)
            if 'ç­–ç•¥æ ‡ç­¾' not in df.columns: df.insert(1, 'ç­–ç•¥æ ‡ç­¾', 'æœªåˆ†ç±»')
            return df
        except Exception: return pd.DataFrame(PRESET_MASTER_DEFAULT)
    return pd.DataFrame(PRESET_MASTER_DEFAULT)

def save_local_config(df):
    try: df.to_pickle(CONFIG_FILE_PATH)
    except Exception as e: st.error(f"é…ç½®ä¿å­˜å¤±è´¥: {e}")

if 'master_data' not in st.session_state: st.session_state.master_data = load_local_config()
if 'portfolios_data' not in st.session_state: st.session_state.portfolios_data = pd.DataFrame(columns=['ç»„åˆåç§°', 'äº§å“åç§°', 'æƒé‡'])

# ------------------------------------------
# 2. UI ç»„ä»¶å°è£… (UI Component)
# ------------------------------------------
def render_grouped_selector(label, options, master_df, key_prefix, default_selections=None):
    if default_selections is None: default_selections = []
    strategy_map = {}
    for p in options:
        tag = "æœªåˆ†ç±»"
        if 'ç­–ç•¥æ ‡ç­¾' in master_df.columns:
            info = master_df[master_df['äº§å“åç§°'] == p]
            if not info.empty: tag = info.iloc[0]['ç­–ç•¥æ ‡ç­¾']
        if pd.isna(tag): tag = "æœªåˆ†ç±»"
        if tag not in strategy_map: strategy_map[tag] = []
        strategy_map[tag].append(p)
    sorted_strategies = sorted(strategy_map.keys(), key=lambda x: (x == "æœªåˆ†ç±»", x))
    final_selection = []
    st.markdown(f"**{label}**")
    for strat in sorted_strategies:
        funds_in_group = strategy_map[strat]
        default_in_group = [f for f in funds_in_group if f in default_selections]
        with st.expander(f"ğŸ“‚ {strat} ({len(funds_in_group)}æ”¯)", expanded=False):
            selected = st.multiselect(f"é€‰æ‹© {strat}", options=funds_in_group, default=default_in_group, key=f"{key_prefix}_{strat}", label_visibility="collapsed")
            final_selection.extend(selected)
    return final_selection

# ------------------------------------------
# 3. ç™»å½•ä¸å®‰å…¨ (Security)
# ------------------------------------------
def check_password():
    if "password_correct" not in st.session_state: st.session_state["password_correct"] = False
    if not st.session_state["password_correct"]:
        st.markdown("<br><br>", unsafe_allow_html=True) 
        st.markdown("<h1 style='text-align: center; color: #1E40AF;'>å¯»æ˜Ÿé…ç½®åˆ†æç³»ç»Ÿ v7.2.0 <small>(Decoupled)</small></h1>", unsafe_allow_html=True)
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            with st.form("login_form"):
                pwd_input = st.text_input(label="ç³»ç»Ÿè®¿é—®å¯†ç ", type="password", placeholder="è¯·è¾“å…¥å¯†ç ")
                if st.form_submit_button("ç«‹å³ç™»å½•", use_container_width=True):
                    if pwd_input == "281699":
                        st.session_state["password_correct"] = True
                        st.rerun()
                    else: st.error("å¯†ç é”™è¯¯ï¼šè®¿é—®æ‹’ç»ã€‚")
        return False
    return True

if check_password():
    # ------------------------------------------
    # 4. æ ¸å¿ƒè®¡ç®—å¼•æ“ (Calculation Engine)
    # ------------------------------------------
    def calculate_net_nav_series(gross_nav_series, mgmt_fee_rate=0.0, perf_fee_rate=0.0):
        if gross_nav_series.empty: return gross_nav_series
        dates = gross_nav_series.index
        gross_vals = gross_nav_series.values
        entry_price = gross_vals[0] 
        net_vals = np.zeros(len(gross_vals)); net_vals[0] = entry_price 
        asset_after_mgmt = np.zeros(len(gross_vals)); asset_after_mgmt[0] = entry_price
        prev_date = dates[0]
        
        for i in range(1, len(gross_vals)):
            r_interval = gross_vals[i] / gross_vals[i-1] - 1
            curr_date = dates[i]
            days_delta = (curr_date - prev_date).days
            mgmt_cost = mgmt_fee_rate * (days_delta / 365.0)
            asset_after_mgmt[i] = asset_after_mgmt[i-1] * (1 + r_interval - mgmt_cost)
            prev_date = curr_date
            
        profits = asset_after_mgmt - entry_price
        liabilities = np.where(profits > 0, profits * perf_fee_rate, 0.0)
        net_vals = np.maximum(asset_after_mgmt - liabilities, 0)
        return pd.Series(net_vals, index=dates)

    def get_drawdown_details(nav_series):
        if nav_series.empty or len(nav_series) < 2: return "æ•°æ®ä¸è¶³", "æ•°æ®ä¸è¶³", pd.Series(dtype='float64')
        cummax = nav_series.cummax()
        drawdown = (nav_series - cummax) / cummax 
        mdd_val = drawdown.min()
        if mdd_val == 0: mdd_recovery = "æ— å›æ’¤"
        else:
            mdd_date = drawdown.idxmin()
            peak_val_at_mdd = cummax.loc[mdd_date]
            post_mdd_data = nav_series.loc[mdd_date:]
            recovery_mask = post_mdd_data >= peak_val_at_mdd
            mdd_recovery = f"{(recovery_mask.idxmax() - mdd_date).days}å¤©" if recovery_mask.any() else "å°šæœªä¿®å¤"
        
        is_at_new_high = (nav_series == cummax)
        high_dates = nav_series[is_at_new_high].index
        if len(high_dates) < 2: max_no_new_high = f"{(nav_series.index[-1] - nav_series.index[0]).days}å¤©"
        else:
            intervals = (high_dates[1:] - high_dates[:-1]).days
            last_gap = (nav_series.index[-1] - high_dates[-1]).days
            max_no_new_high = f"{max(intervals.max(), last_gap) if len(intervals)>0 else last_gap}å¤©"
        return mdd_recovery, max_no_new_high, drawdown

    def calculate_capture_stats(nav_series, bench_series, period_name):
        """
        [v7.1.3 Fix] æ™ºèƒ½æ•è·ç‡ç®—æ³•
        """
        if nav_series.empty or len(nav_series) < 2:
            return {"æ—¶æ®µ": period_name, "ä¸Šè¡Œæ•è·": np.nan, "ä¸‹è¡Œæ•è·": np.nan, "CIOç‚¹è¯„": "æ•°æ®ä¸è¶³"}
        
        p_rets = nav_series.pct_change().dropna()
        b_rets = bench_series.pct_change().dropna()
        valid_idx = p_rets.index.intersection(b_rets.index)
        
        if len(valid_idx) < 1:
            return {"æ—¶æ®µ": period_name, "ä¸Šè¡Œæ•è·": np.nan, "ä¸‹è¡Œæ•è·": np.nan, "CIOç‚¹è¯„": "æ— é‡å æ•°æ®"}
            
        p_rets = p_rets.loc[valid_idx]
        b_rets = b_rets.loc[valid_idx]

        def safe_capture_ratio(p_segment, b_segment):
            if b_segment.empty: return 0.0
            b_mean = b_segment.mean()
            p_mean = p_segment.mean()
            if abs(b_mean) < 0.0005: return 0.0 
            return p_mean / b_mean

        up_mask = b_rets > 0
        down_mask = b_rets < 0
        
        up_cap = safe_capture_ratio(p_rets[up_mask], b_rets[up_mask])
        down_cap = safe_capture_ratio(p_rets[down_mask], b_rets[down_mask])
            
        comment = "æ­£å¸¸"
        if abs(down_cap) > 5.0: comment = "âš ï¸ æ•°æ®å¼‚å¸¸(åŸºå‡†å¾®åŠ¨)"
        elif down_cap < 0: comment = "ğŸ›¡ï¸ é€†å¸‚æ”¶ç›Š (Alpha)"
        elif down_cap > 1.0 and up_cap < 0.8: comment = "âš ï¸ ç­–ç•¥å¤±æ•ˆ"
        elif down_cap < 0.8 and up_cap > 0.9: comment = "ğŸ’ æ”»å®ˆå…¼å¤‡"
        
        return {"æ—¶æ®µ": period_name, "ä¸Šè¡Œæ•è·": up_cap, "ä¸‹è¡Œæ•è·": down_cap, "CIOç‚¹è¯„": comment}

    # [New] è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ ¸å¿ƒç®—æ³• (Updated for Frequency)
    def run_monte_carlo(period_returns, n_sims=1000, n_steps=252):
        if period_returns.empty: return None
        
        mu = period_returns.mean()
        sigma = period_returns.std()
        last_price = 1.0 
        
        # å‡ ä½•å¸ƒæœ—è¿åŠ¨ (Geometric Brownian Motion)
        # è¿™é‡Œçš„ n_steps ä»£è¡¨æœªæ¥çš„â€œå‘¨æœŸæ•°â€ï¼Œè€Œéå¤©æ•°
        dt = 1 
        drift = (mu - 0.5 * sigma**2) * dt
        shock = sigma * np.sqrt(dt) * np.random.normal(0, 1, (n_steps, n_sims))
        
        period_returns_sim = np.exp(drift + shock)
        price_paths = np.zeros((n_steps + 1, n_sims))
        price_paths[0] = last_price
        
        for t in range(1, n_steps + 1):
            price_paths[t] = price_paths[t-1] * period_returns_sim[t-1]
            
        return price_paths

    def get_freq_factor(nav):
        # è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—å¹´åŒ–å› å­
        if len(nav) < 2: return 252.0
        dates = nav.index
        count = len(dates) - 1
        days_diff = (dates[-1] - dates[0]).days
        avg_interval = days_diff / count if count > 0 else 1
        
        if avg_interval <= 1.5: return 252.0  # Daily
        elif avg_interval <= 8: return 52.0   # Weekly
        elif avg_interval <= 35: return 12.0  # Monthly
        else: return 252.0 / avg_interval

    def calculate_metrics(nav, bench_nav=None):
        nav = nav.dropna()
        if len(nav) < 2: return {}
        
        dates = nav.index
        days_diff = (dates[-1] - dates[0]).days
        if days_diff <= 0: return {}
        
        freq_factor = get_freq_factor(nav)
        
        returns = nav.pct_change().dropna()
        total_ret = (nav.iloc[-1] / nav.iloc[0]) - 1
        ann_ret = (1 + total_ret) ** (365.25 / days_diff) - 1
        vol = returns.std() * np.sqrt(freq_factor)
        mdd_rec, max_nh, dd_s = get_drawdown_details(nav)
        mdd = dd_s.min()
        
        rf = 0.015 
        excess_ret = ann_ret - rf
        sharpe = excess_ret / vol if vol > 1e-6 else 0.0
        
        downside_diff = returns - (rf / freq_factor)
        downside_diff = downside_diff[downside_diff < 0]
        if not downside_diff.empty:
            downside_std = np.sqrt((downside_diff ** 2).mean()) * np.sqrt(freq_factor)
        else: downside_std = 1e-6
        sortino = excess_ret / downside_std if downside_std > 1e-6 else 0.0
        
        calmar = ann_ret / abs(mdd) if abs(mdd) > 1e-6 else 0.0
        
        win_days = returns[returns > 0]; loss_days = returns[returns < 0]
        avg_win = win_days.mean() if not win_days.empty else 0
        avg_loss = abs(loss_days.mean()) if not loss_days.empty else 0
        pl_ratio = avg_win / avg_loss if avg_loss > 0 else 0
        var_95 = np.percentile(returns, 5) 

        metrics = {
            "æ€»æ”¶ç›Šç‡": total_ret, "å¹´åŒ–æ”¶ç›Š": ann_ret, "æœ€å¤§å›æ’¤": mdd, 
            "å¤æ™®æ¯”ç‡": sharpe, "ç´¢æè¯ºæ¯”ç‡": sortino, "å¡ç›æ¯”ç‡": calmar, "å¹´åŒ–æ³¢åŠ¨ç‡": vol,
            "æœ€å¤§å›æ’¤ä¿®å¤æ—¶é—´": mdd_rec, "æœ€å¤§æ— æ–°é«˜æŒç»­æ—¶é—´": max_nh,
            "æ­£æ”¶ç›Šæ¦‚ç‡(æ—¥)": len(win_days) / len(returns) if len(returns) > 0 else 0,
            "ç›ˆäºæ¯”": pl_ratio, "VaR(95%)": var_95, "dd_series": dd_s,
            "Beta": 0.0, "Current_Beta": 0.0, "Alpha": 0.0, "ä¸Šè¡Œæ•è·": 0.0, "ä¸‹è¡Œæ•è·": 0.0,
            "Rolling_Beta_Series": pd.Series(dtype='float64'),
            "Rolling_Up_Cap": pd.Series(dtype='float64'), "Rolling_Down_Cap": pd.Series(dtype='float64'),
            "freq_factor": freq_factor
        }
        
        if bench_nav is not None:
            common_idx = nav.index.intersection(bench_nav.index)
            if len(common_idx) > 10:
                p_rets = nav.loc[common_idx].pct_change().dropna()
                b_rets = bench_nav.loc[common_idx].pct_change().dropna()
                valid_idx = p_rets.index.intersection(b_rets.index)
                p_rets = p_rets.loc[valid_idx]; b_rets = b_rets.loc[valid_idx]
                
                if not p_rets.empty:
                    cov_mat = np.cov(p_rets, b_rets)
                    beta = cov_mat[0, 1] / cov_mat[1, 1] if cov_mat.shape == (2, 2) and cov_mat[1, 1] != 0 else 0
                    bench_total_ret = (bench_nav.loc[common_idx[-1]]/bench_nav.loc[common_idx[0]])**(365.25/(common_idx[-1]-common_idx[0]).days) - 1
                    alpha = ann_ret - (rf + beta * (bench_total_ret - rf))

                    window = int(freq_factor / 2)
                    if window < 10: window = 10
                    rolling_betas = []; rolling_dates = []; rolling_up_cap = []; rolling_down_cap = []

                    if len(p_rets) > window:
                        for i in range(window, len(p_rets)):
                            r_win = p_rets.iloc[i-window:i]
                            b_win = b_rets.iloc[i-window:i]
                            current_date = p_rets.index[i]
                            
                            var_b = b_win.var()
                            cov_rb = r_win.cov(b_win)
                            rb = cov_rb / var_b if var_b != 0 else 0
                            
                            up_mask_win = b_win > 0; down_mask_win = b_win < 0
                            r_up_val = (r_win[up_mask_win].mean() / b_win[up_mask_win].mean()) if (up_mask_win.any() and abs(b_win[up_mask_win].mean()) > 1e-6) else 0
                            r_down_val = (r_win[down_mask_win].mean() / b_win[down_mask_win].mean()) if (down_mask_win.any() and abs(b_win[down_mask_win].mean()) > 1e-6) else 0
                                
                            rolling_betas.append(rb)
                            rolling_up_cap.append(r_up_val)
                            rolling_down_cap.append(r_down_val)
                            rolling_dates.append(current_date)
                            
                        curr_beta = rolling_betas[-1] if rolling_betas else beta
                        rb_series = pd.Series(rolling_betas, index=rolling_dates)
                        ru_series = pd.Series(rolling_up_cap, index=rolling_dates)
                        rd_series = pd.Series(rolling_down_cap, index=rolling_dates)
                    else:
                        curr_beta = beta
                        rb_series = pd.Series([beta]*len(p_rets), index=p_rets.index)
                        ru_series = pd.Series(dtype='float64'); rd_series = pd.Series(dtype='float64')
                    
                    up_mask = b_rets > 0; down_mask = b_rets < 0
                    up_cap = (p_rets[up_mask].mean() / b_rets[up_mask].mean()) if (up_mask.any() and abs(b_rets[up_mask].mean()) > 1e-6) else 0
                    down_cap = (p_rets[down_mask].mean() / b_rets[down_mask].mean()) if (down_mask.any() and abs(b_rets[down_mask].mean()) > 1e-6) else 0

                    metrics.update({
                        "ä¸Šè¡Œæ•è·": up_cap, "ä¸‹è¡Œæ•è·": down_cap, "Beta": beta, "Current_Beta": curr_beta, "Alpha": alpha,
                        "Rolling_Beta_Series": rb_series, "Rolling_Up_Cap": ru_series, "Rolling_Down_Cap": rd_series    
                    })
        return metrics

    def calculate_liquidity_risk(weights, master_df):
        w_series = pd.Series(weights)
        w_norm = w_series / w_series.sum()
        weighted_lockup = 0.0; worst_lockup = 0; liquidity_notes = []
        for p, w in w_norm.items():
            info = master_df[master_df['äº§å“åç§°'] == p]
            if not info.empty:
                lock = info.iloc[0].get('é”å®šæœŸ(æœˆ)', 6)
                weighted_lockup += lock * w
                if lock > worst_lockup: worst_lockup = lock
                if lock >= 12: liquidity_notes.append(f"âš ï¸ {p}({lock}ä¸ªæœˆ)")
            else: weighted_lockup += 6 * w 
        return weighted_lockup, worst_lockup, liquidity_notes

    # ------------------------------------------
    # 5. UI ç•Œé¢ä¸äº¤äº’ (Interface)
    # ------------------------------------------
    st.set_page_config(layout="wide", page_title="å¯»æ˜Ÿé…ç½®åˆ†æç³»ç»Ÿ v7.2.0", page_icon="ğŸ›ï¸")
    st.sidebar.title("ğŸ›ï¸ å¯»æ˜Ÿ v7.2.0 Â· é©¾é©¶èˆ±")
    uploaded_file = st.sidebar.file_uploader("ğŸ“‚ ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ å‡€å€¼æ•°æ®åº“ (.xlsx)", type=["xlsx"])

    if uploaded_file:
        df_raw = pd.read_excel(uploaded_file, index_col=0, parse_dates=True).sort_index().ffill()
        df_raw.columns = [str(c).strip() for c in df_raw.columns]
        all_cols = df_raw.columns.tolist()
        
        st.sidebar.markdown("---")
        with st.sidebar.expander("âš™ï¸ å¯»æ˜Ÿé…ç½®å‚æ•°", expanded=False):
            st.info("ğŸ’¡ ç³»ç»Ÿå·²å¯ç”¨è‡ªåŠ¨è®°å¿†ï¼šæ‚¨åœ¨æ­¤å¤„çš„ä¿®æ”¹ä¼šè‡ªåŠ¨ä¿å­˜ï¼Œä¸‹æ¬¡æ— éœ€é‡æ–°è¾“å…¥ã€‚")
            col_bk1, col_bk2 = st.columns(2)
            uploaded_backup = col_bk1.file_uploader("ğŸ“¥ æ¢å¤å…¨é‡å¤‡ä»½", type=['xlsx'])
            if uploaded_backup:
                try:
                    df_master_new = pd.read_excel(uploaded_backup, sheet_name='Master_Data')
                    st.session_state.master_data = df_master_new
                    save_local_config(df_master_new) 
                    try:
                        df_port_new = pd.read_excel(uploaded_backup, sheet_name='Portfolios')
                        st.session_state.portfolios_data = df_port_new
                        st.toast("âœ… è´¹ç‡ä¸ç»„åˆæ•°æ®æ¢å¤æˆåŠŸï¼", icon="ğŸ‰")
                    except: st.toast("âš ï¸ ä»…æ¢å¤äº†è´¹ç‡ï¼Œæœªæ‰¾åˆ°ç»„åˆæ•°æ®ã€‚", icon="â„¹ï¸")
                except Exception as e: st.error(f"æ¢å¤å¤±è´¥: {e}")

            current_products = st.session_state.master_data['äº§å“åç§°'].tolist()
            new_products = [p for p in all_cols if p not in current_products and p not in ['æ²ªæ·±300', 'æ—¥æœŸ']]
            if new_products:
                new_rows = []
                for p in new_products:
                    row = DEFAULT_MASTER_ROW.copy(); row['äº§å“åç§°'] = p
                    new_rows.append(row)
                st.session_state.master_data = pd.concat([st.session_state.master_data, pd.DataFrame(new_rows)], ignore_index=True)
                save_local_config(st.session_state.master_data) 
            
            edited_master = st.data_editor(st.session_state.master_data, column_config={
                "ç­–ç•¥æ ‡ç­¾": st.column_config.SelectboxColumn(options=["ä¸»è§‚å¤šå¤´", "é‡åŒ–æŒ‡å¢", "é‡åŒ–ä¸­æ€§", "é‡åŒ–å¯¹å†²", "é‡åŒ–é€‰è‚¡", "æœŸæƒå¥—åˆ©", "CTA", "å¤šç­–ç•¥", "æœªåˆ†ç±»"], required=True),
                "å¼€æ”¾é¢‘ç‡": st.column_config.SelectboxColumn(options=["å‘¨åº¦", "æœˆåº¦", "å­£åº¦", "åŠå¹´", "1å¹´", "3å¹´å°é—­"])
            }, use_container_width=True, hide_index=True, key="master_editor_v700")
            
            if not edited_master.equals(st.session_state.master_data):
                st.session_state.master_data = edited_master
                save_local_config(edited_master) 
            
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                st.session_state.master_data.to_excel(writer, sheet_name='Master_Data', index=False)
                st.session_state.portfolios_data.to_excel(writer, sheet_name='Portfolios', index=False)
            st.download_button(label="ğŸ’¾ ä¸‹è½½å¯»æ˜Ÿé…ç½®å‚æ•° (.xlsx)", data=buffer, file_name="å¯»æ˜Ÿ_å…¨é‡ç³»ç»Ÿå¤‡ä»½.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
            MASTER_DICT = {row['äº§å“åç§°']: row.to_dict() for _, row in st.session_state.master_data.iterrows()}

        st.sidebar.markdown("---")
        st.sidebar.markdown("### ğŸ’¼ ç»„åˆé…ç½®")
        saved_names = st.session_state.portfolios_data['ç»„åˆåç§°'].unique().tolist() if not st.session_state.portfolios_data.empty else []
        mode_options = ["ğŸ› ï¸ è‡ªå®šä¹‰/æ–°å»º"] + saved_names
        selected_mode = st.sidebar.selectbox("é€‰æ‹©æ¨¡å¼:", mode_options)
        
        sel_funds = []; weights = {}
        default_bench = 'æ²ªæ·±300' if 'æ²ªæ·±300' in all_cols else all_cols[0]
        sel_bench = st.sidebar.selectbox("ä¸šç»©åŸºå‡†", all_cols, index=all_cols.index(default_bench))
        
        if selected_mode == "ğŸ› ï¸ è‡ªå®šä¹‰/æ–°å»º":
            available_funds = sorted([c for c in all_cols if c != sel_bench])
            with st.sidebar:
                sel_funds = render_grouped_selector("æŒ‘é€‰æˆåˆ†åŸºé‡‘ (æŒ‰ç­–ç•¥)", available_funds, st.session_state.master_data, key_prefix="sidebar_select")
            if sel_funds:
                st.sidebar.markdown("#### âš–ï¸ æƒé‡")
                avg_w = 1.0 / len(sel_funds)
                for f in sel_funds: weights[f] = st.sidebar.number_input(f"{f}", 0.0, 1.0, avg_w, step=0.05)
                with st.sidebar.expander("ğŸ’¾ ä¿å­˜ç»„åˆ", expanded=True):
                    new_p_name = st.text_input("ç»„åˆåç§°", placeholder="å¦‚: ç¨³å¥1å·")
                    if st.button("ä¿å­˜") and new_p_name and sel_funds:
                        new_records = [{'ç»„åˆåç§°': new_p_name, 'äº§å“åç§°': f, 'æƒé‡': w} for f, w in weights.items()]
                        old_df = st.session_state.portfolios_data
                        new_df = pd.DataFrame(new_records)
                        updated_df = pd.concat([old_df[old_df['ç»„åˆåç§°']!=new_p_name], new_df], ignore_index=True)
                        st.session_state.portfolios_data = updated_df
                        st.toast(f"ç»„åˆ {new_p_name} å·²ä¿å­˜", icon="âœ…")
                        st.rerun()
        else:
            subset = st.session_state.portfolios_data[st.session_state.portfolios_data['ç»„åˆåç§°'] == selected_mode]
            valid_subset = subset[subset['äº§å“åç§°'].isin(all_cols)]
            sel_funds = valid_subset['äº§å“åç§°'].tolist()
            weights = {row['äº§å“åç§°']: row['æƒé‡'] for _, row in valid_subset.iterrows()}
            st.sidebar.table(valid_subset[['äº§å“åç§°', 'æƒé‡']].set_index('äº§å“åç§°').style.format("{:.1%}"))
            if st.sidebar.button("ğŸ—‘ï¸ åˆ é™¤æ­¤ç»„åˆ"):
                updated = st.session_state.portfolios_data[st.session_state.portfolios_data['ç»„åˆåç§°'] != selected_mode]
                st.session_state.portfolios_data = updated
                st.rerun()

        color_map = {}
        if sel_funds:
            colors = px.colors.qualitative.Plotly 
            for i, f in enumerate(sel_funds): color_map[f] = colors[i % len(colors)]

        st.sidebar.markdown("---")
        fee_mode_label = "ç»„åˆå®å¾—å›æŠ¥"
        if sel_funds: fee_mode_label = st.sidebar.radio("å±•ç¤ºè§†è§’", ("ç»„åˆå®å¾—å›æŠ¥", "ç»„åˆç­–ç•¥è¡¨ç°", "æ”¶ç›Šä¸è¿ä½œæˆæœ¬åˆ†æ"), index=0)

        # ==========================================
        # [Critical Fix v7.1.1] é»˜è®¤è§†è§’é”šå®š 2020-01-01
        # ==========================================
        st.sidebar.markdown("### â³ å›æµ‹åŒºé—´ (Global Time Window)")
        
        # 1. è·å–æ•°æ®çš„ç»å¯¹è¾¹ç•Œ
        data_min_date = df_raw.index.min().date()
        data_max_date = df_raw.index.max().date()
        
        # 2. æ™ºèƒ½è®¡ç®—é»˜è®¤èµ·å§‹æ—¥ (Target: 2020-01-01)
        target_start = pd.Timestamp("2020-01-01").date()
        
        if target_start < data_min_date:
            default_start = data_min_date  
        elif target_start > data_max_date:
            default_start = data_min_date  
        else:
            default_start = target_start   # âœ… æ­£å¸¸å‘½ä¸­ 2020-01-01
        
        # 3. æ¸²æŸ“æ—¥æœŸé€‰æ‹©å™¨
        start_date = st.sidebar.date_input(
            "èµ·å§‹æ—¥æœŸ", 
            value=default_start,    # æ™ºèƒ½é»˜è®¤å€¼
            min_value=data_min_date, 
            max_value=data_max_date
        )
        end_date = st.sidebar.date_input(
            "æˆªæ­¢æ—¥æœŸ", 
            value=data_max_date, 
            min_value=data_min_date, 
            max_value=data_max_date
        )
        
        # 4. é€»è¾‘é˜²å‘†
        if start_date >= end_date:
            st.error("âŒ é”™è¯¯ï¼šèµ·å§‹æ—¥æœŸå¿…é¡»æ—©äºæˆªæ­¢æ—¥æœŸã€‚")
            st.stop()
            
        # 5. æ‰§è¡Œåˆ‡ç‰‡
        df_db = df_raw.loc[start_date:end_date].copy()
        
        # ==========================================
        
        star_nav = None; star_nav_gross = None; star_nav_net = None

        if sel_funds and not df_db.empty:
            df_port = df_db[sel_funds].ffill().dropna(how='all') 
            
            if not df_port.empty:
                norm_w = pd.Series(weights) / (sum(weights.values()) if sum(weights.values()) > 0 else 1)
                
                # Gross Calculation
                star_rets_gross = (df_port.pct_change().fillna(0) * norm_w).sum(axis=1) 
                star_nav_gross = (1 + star_rets_gross).cumprod()
                star_nav_gross.name = "ç»„åˆç­–ç•¥è¡¨ç°"

                # Net Calculation
                net_funds_df = pd.DataFrame(index=df_port.index)
                for f in sel_funds:
                    s_raw = df_db[f].dropna()
                    if s_raw.empty: continue
                    s_segment = s_raw.reindex(df_port.index)
                    s_segment = s_segment.fillna(method='bfill').fillna(1.0)
                    
                    info = MASTER_DICT.get(f, DEFAULT_MASTER_ROW)
                    mgmt = info.get('å¹´ç®¡ç†è´¹(%)', 0) / 100.0
                    perf = info.get('ä¸šç»©æŠ¥é…¬(%)', 0) / 100.0
                    net_funds_df[f] = calculate_net_nav_series(s_segment, mgmt, perf)

                if fee_mode_label != "ç»„åˆç­–ç•¥è¡¨ç°":
                    star_rets_net = (net_funds_df.pct_change().fillna(0) * norm_w).sum(axis=1)
                    star_nav_net = (1 + star_rets_net).cumprod()
                    star_nav_net.name = "ç»„åˆå®å¾—å›æŠ¥"

                star_nav = star_nav_gross if fee_mode_label == "ç»„åˆç­–ç•¥è¡¨ç°" else star_nav_net
                bn_sync = df_db.loc[star_nav.index, sel_bench]
                bn_norm = bn_sync / bn_sync.iloc[0]

        tabs = st.tabs(["âš”ï¸ é…ç½®æ± äº§å“åˆ†æ", "ğŸš€ ç»„åˆå…¨æ™¯å›¾", "ğŸ” ç©¿é€å½’å› åˆ†æ", "ğŸŒªï¸ é£é™©é£æ´å®éªŒå®¤"])

        if star_nav is not None:
            m = calculate_metrics(star_nav, bn_sync)
            avg_lock, worst_lock, lock_notes = calculate_liquidity_risk(weights, st.session_state.master_data)

        # === Tab 1 ===
        with tabs[0]:
            c_t1, c_t2 = st.columns([3, 1])
            with c_t1: st.subheader("âš”ï¸ é…ç½®æ± äº§å“åˆ†æ")
            with c_t2: comp_fee_mode = st.selectbox("å±•ç¤ºè§†è§’", ["è´¹å‰ (Gross)", "è´¹å (Net)"], index=0)
            pool_options = sorted([c for c in all_cols if c != sel_bench])
            compare_pool = render_grouped_selector("æœç´¢æ± å†…äº§å“ (æŒ‰ç­–ç•¥)", pool_options, st.session_state.master_data, key_prefix="pool_select")
            
            if compare_pool:
                is_aligned = st.checkbox("å¯¹é½èµ·å§‹æ—¥æœŸæ¯”è¾ƒ", value=False)
                df_comp_raw = df_db[compare_pool].dropna() if is_aligned else df_db[compare_pool]
                
                if comp_fee_mode == "è´¹å (Net)":
                    df_comp = pd.DataFrame(index=df_comp_raw.index)
                    for p in compare_pool:
                        s_raw = df_comp_raw[p].dropna()
                        if s_raw.empty: continue
                        info = MASTER_DICT.get(p, DEFAULT_MASTER_ROW)
                        df_comp[p] = calculate_net_nav_series(s_raw, info.get('å¹´ç®¡ç†è´¹(%)', 0)/100.0, info.get('ä¸šç»©æŠ¥é…¬(%)', 0)/100.0)
                else: df_comp = df_comp_raw

                if not df_comp.empty:
                    fig_p = go.Figure()
                    for col in compare_pool:
                        if col in df_comp.columns:
                            s = df_comp[col].dropna()
                            if not s.empty: fig_p.add_trace(go.Scatter(x=s.index, y=s/s.iloc[0], name=col))
                    
                    if sel_bench in df_db.columns:
                        s_bench = df_db[sel_bench].reindex(df_comp.index).ffill()
                        if not s_bench.empty:
                            s_bench = s_bench / s_bench.iloc[0]
                            fig_p.add_trace(go.Scatter(x=s_bench.index, y=s_bench, name=f"åŸºå‡†: {sel_bench}", line=dict(color='#1890FF', width=2, dash='solid'), opacity=0.8))

                    st.plotly_chart(fig_p.update_layout(title=f"ä¸šç»©å¯¹æ¯” ({comp_fee_mode})", template="plotly_white", height=500), use_container_width=True)
                    
                    res_data = []
                    for col in compare_pool:
                        if col in df_comp.columns:
                            s_full = df_comp[col].dropna()
                            if s_full.empty: continue
                            
                            b_full = df_db[sel_bench].reindex(s_full.index).dropna()
                            common_idx = s_full.index.intersection(b_full.index)
                            s_final = s_full.loc[common_idx]
                            b_final = b_full.loc[common_idx]
                            if len(s_final) < 10: continue

                            k = calculate_metrics(s_final, b_final)
                            if not k: continue

                            freq_n = int(k.get('freq_factor', 252)) 
                            window_1y = freq_n
                            window_6m = max(int(freq_n / 2), 1)

                            if len(s_final) >= window_1y:
                                cap_1y = calculate_capture_stats(s_final.iloc[-window_1y:], b_final.iloc[-window_1y:], "L1Y")
                                l1y_up = f"{cap_1y['ä¸Šè¡Œæ•è·']:.2%}"
                                l1y_down = f"{cap_1y['ä¸‹è¡Œæ•è·']:.2%}"
                            else: l1y_up, l1y_down = "-", "-"

                            if len(s_final) >= window_6m:
                                cap_6m = calculate_capture_stats(s_final.iloc[-window_6m:], b_final.iloc[-window_6m:], "L6M")
                                l6m_up = f"{cap_6m['ä¸Šè¡Œæ•è·']:.2%}"
                                l6m_down = f"{cap_6m['ä¸‹è¡Œæ•è·']:.2%}"
                            else: l6m_up, l6m_down = "-", "-"

                            res_data.append({
                                "äº§å“åç§°": col, 
                                "æ€»æ”¶ç›Š": f"{k['æ€»æ”¶ç›Šç‡']:.2%}", "å¹´åŒ–æ”¶ç›Š": f"{k['å¹´åŒ–æ”¶ç›Š']:.2%}", "æœ€å¤§å›æ’¤": f"{k['æœ€å¤§å›æ’¤']:.2%}",
                                "å¡ç›": f"{k['å¡ç›æ¯”ç‡']:.2f}", "å¤æ™®": f"{k['å¤æ™®æ¯”ç‡']:.2f}", "ç´¢æè¯º": f"{k['ç´¢æè¯ºæ¯”ç‡']:.2f}",
                                "å…¨æ™¯ä¸Šè¡Œ": f"{k['ä¸Šè¡Œæ•è·']:.2%}", "å…¨æ™¯ä¸‹è¡Œ": f"{k['ä¸‹è¡Œæ•è·']:.2%}",
                                "è¿‘1å¹´ä¸Šè¡Œ": l1y_up, "è¿‘1å¹´ä¸‹è¡Œ": l1y_down,
                                "è¿‘åŠå¹´ä¸Šè¡Œ": l6m_up, "è¿‘åŠå¹´ä¸‹è¡Œ": l6m_down,
                                "èƒœç‡": f"{k['æ­£æ”¶ç›Šæ¦‚ç‡(æ—¥)']:.1%}", "VaR(95%)": f"{k['VaR(95%)']:.2%}",
                                "Alpha": f"{k['Alpha']:.2%}", "Beta": f"{k['Beta']:.2f}"
                            })
                    if res_data: st.dataframe(pd.DataFrame(res_data).set_index('äº§å“åç§°'), use_container_width=True)
                    
                    st.markdown("#### ğŸ“… åˆ†å¹´åº¦æ”¶ç›Šç‡ç»Ÿè®¡")
                    yearly_data = {}
                    for col in compare_pool:
                        if col in df_comp.columns:
                            s = df_comp[col].dropna()
                            groups = s.groupby(s.index.year)
                            y_vals = {}
                            for year, group in groups: y_vals[year] = (group.iloc[-1] / group.iloc[0]) - 1
                            yearly_data[col] = y_vals
                    if yearly_data:
                        df_yearly = pd.DataFrame(yearly_data).T
                        st.dataframe(df_yearly[sorted(df_yearly.columns)].style.format("{:.2%}"), use_container_width=True)
                else: st.warning("âš ï¸ æ•°æ®ä¸è¶³")
            st.markdown("---"); st.info("ğŸ“š å¯»æ˜ŸÂ·é‡åŒ–æŒ‡æ ‡è¯´æ˜ï¼šå…¨ç«™å·²ç»Ÿä¸€ä¸ºç™¾åˆ†æ¯”æ ¼å¼ï¼Œå¹¶æ”¯æŒå‘¨é¢‘/æœˆé¢‘æ•°æ®çš„çŸ­æœŸæŒ‡æ ‡è®¡ç®—ã€‚")

        # === Tab 2 ===
        with tabs[1]:
            if star_nav is not None:
                st.subheader(f"ğŸ“Š {star_nav.name}")
                c_top = st.columns(8)
                c_top[0].metric("æ€»æ”¶ç›Šç‡", f"{m['æ€»æ”¶ç›Šç‡']:.2%}")
                c_top[1].metric("å¹´åŒ–æ”¶ç›Š", f"{m['å¹´åŒ–æ”¶ç›Š']:.2%}")
                c_top[2].metric("æœ€å¤§å›æ’¤", f"{m['æœ€å¤§å›æ’¤']:.2%}")
                c_top[3].metric("å¤æ™®æ¯”ç‡", f"{m['å¤æ™®æ¯”ç‡']:.2f}")
                c_top[4].metric("ç´¢æè¯º", f"{m['ç´¢æè¯ºæ¯”ç‡']:.2f}")
                c_top[5].metric("å¡ç›æ¯”ç‡", f"{m['å¡ç›æ¯”ç‡']:.2f}")
                c_top[6].metric("å¹´åŒ–æ³¢åŠ¨", f"{m['å¹´åŒ–æ³¢åŠ¨ç‡']:.2%}")
                c_top[7].metric("ç»„åˆBeta", f"{m['Beta']:.2f}")
                
                fig_main = go.Figure()
                if fee_mode_label == "æ”¶ç›Šä¸è¿ä½œæˆæœ¬åˆ†æ":
                    fig_main.add_trace(go.Scatter(x=star_nav_net.index, y=star_nav_net, name="ç»„åˆå®å¾—å›æŠ¥", line=dict(color='red', width=3)))
                    fig_main.add_trace(go.Scatter(x=star_nav_gross.index, y=star_nav_gross, name="ç»„åˆç­–ç•¥è¡¨ç°", line=dict(color='gray', width=2, dash='dash')))
                else:
                    fig_main.add_trace(go.Scatter(x=star_nav.index, y=star_nav, name=star_nav.name, line=dict(color='red', width=4)))
                
                fig_main.add_trace(go.Scatter(x=bn_norm.index, y=bn_norm, name=f"åŸºå‡†: {sel_bench}", line=dict(color='#1890FF', width=2, dash='solid'), opacity=0.8))
                fig_main.update_layout(title="è´¦æˆ·æƒç›Šèµ°åŠ¿", template="plotly_white", hovermode="x unified", height=450)
                st.plotly_chart(fig_main, use_container_width=True)

                st.markdown("#### ğŸ›¡ï¸ é£é™©ä½“éªŒä¸é£æ ¼ç›‘æ§")
                c_risk = st.columns(5) 
                c_risk[0].metric("æœ€å¤§å›æ’¤ä¿®å¤", m['æœ€å¤§å›æ’¤ä¿®å¤æ—¶é—´'])
                c_risk[1].metric("æœ€é•¿åˆ›æ–°é«˜é—´éš”", m['æœ€å¤§æ— æ–°é«˜æŒç»­æ—¶é—´'])
                c_risk[2].metric("ç›ˆäºæ¯”", f"{m['ç›ˆäºæ¯”']:.2f}")
                c_risk[3].metric("Current Beta", f"{m['Current_Beta']:.2f}")
                c_risk[4].metric("VaR (95%)", f"{m['VaR(95%)']:.2%}")
                if abs(m['Current_Beta'] - m['Beta']) > 0.1: st.warning(f"âš ï¸ **é£æ ¼æ¼‚ç§»é¢„è­¦**ï¼šBeta åå·® {abs(m['Current_Beta'] - m['Beta']):.2f}ã€‚")
                if lock_notes: st.warning(f"âš ï¸ **æµåŠ¨æ€§è­¦ç¤º**ï¼š{' '.join(lock_notes)}")
            else: st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©æˆ–åŠ è½½ç»„åˆã€‚")

        # === Tab 3 ===
        with tabs[2]:
            if sel_funds:
                st.subheader("ğŸ” å¯»æ˜Ÿé…ç½®ç©¿é€å½’å› åˆ†æ")
                if fee_mode_label == "ç»„åˆç­–ç•¥è¡¨ç°": df_attr = df_port
                else: df_attr = net_funds_df
                
                # [Core Logic: Contribution View uses Cash Filled Data]
                growth_factors = pd.Series(index=df_attr.columns, dtype=float)
                for col in df_attr.columns:
                    s = df_attr[col]
                    if not s.empty: growth_factors[col] = s.iloc[-1] / s.iloc[0]
                    else: growth_factors[col] = 1.0 

                initial_w_series = pd.Series(weights) / (sum(weights.values()) if sum(weights.values()) > 0 else 1)
                latest_values = initial_w_series * growth_factors
                latest_w_series = latest_values / latest_values.sum()

                col_w1, col_w2 = st.columns(2)
                col_w1.plotly_chart(px.pie(names=initial_w_series.index, values=initial_w_series.values, hole=0.4, title="åˆå§‹é…ç½®æ¯”ä¾‹", color=initial_w_series.index, color_discrete_map=color_map), use_container_width=True)
                col_w2.plotly_chart(px.pie(names=latest_w_series.index, values=latest_w_series.values, hole=0.4, title="æœ€æ–°é…ç½®æ¯”ä¾‹(æ¼‚ç§»)", color=latest_w_series.index, color_discrete_map=color_map), use_container_width=True)

                if not m['Rolling_Beta_Series'].empty:
                    st.markdown("#### ğŸ“‰ é£æ ¼åŠ¨æ€å½’å› ï¼šBeta æ¼‚ç§»è·¯å¾„")
                    fig_beta = go.Figure()
                    fig_beta.add_trace(go.Scatter(x=m['Rolling_Beta_Series'].index, y=m['Rolling_Beta_Series'], name="æ»šåŠ¨åŠå¹´ Beta", line=dict(color='#2563EB', width=2)))
                    fig_beta.add_hline(y=m['Beta'], line_dash="dash", line_color="green", annotation_text="å…¨å‘¨æœŸå‡å€¼")
                    fig_beta.update_layout(template="plotly_white", height=350, hovermode="x unified")
                    st.plotly_chart(fig_beta, use_container_width=True)

                if not m['Rolling_Up_Cap'].empty and not m['Rolling_Down_Cap'].empty:
                    st.markdown("#### ğŸŒŠ åŠ¨æ€æ”»å®ˆèƒ½åŠ›åˆ†æ (Dynamic Capture Analysis)")
                    
                    st.markdown("##### 1. åˆ†æ—¶æ®µæ”»å®ˆèƒ½åŠ›é›·è¾¾ (Static Period Radar)")
                    st.info("ğŸ’¡ **æ¶æ„å¸ˆæ³¨**ï¼šä»¥ä¸‹æŒ‡æ ‡åŸºäºå„åŸºé‡‘**å®é™…æˆç«‹/å­˜ç»­åŒºé—´**è®¡ç®— (Raw Data)ï¼Œå·²å‰”é™¤æœªæŠ•å…¥æœŸçš„ç°é‡‘æ‹–ç´¯ã€‚")
                    
                    # [Dual-Track: Asset Analysis View uses Raw Data]
                    metrics_list = []
                    for col in sel_funds:
                        s_raw = df_db[col].dropna()
                        if s_raw.empty: continue
                        b_raw = df_db[sel_bench].reindex(s_raw.index).dropna()
                        common_idx = s_raw.index.intersection(b_raw.index)
                        s_final = s_raw.loc[common_idx]
                        b_final = b_raw.loc[common_idx]
                        if len(s_final) < 10: continue
                        
                        cap_stats = calculate_capture_stats(s_final, b_final, "å…¨å‘¨æœŸ")
                        m_real = calculate_metrics(s_final, b_final)
                        
                        metrics_list.append({
                            "äº§å“åç§°": col,
                            "å­˜ç»­æ—¶é•¿": f"{(s_final.index[-1] - s_final.index[0]).days}å¤©",
                            "å¹´åŒ–æ”¶ç›Š": f"{m_real['å¹´åŒ–æ”¶ç›Š']:.2%}",
                            "æœ€å¤§å›æ’¤": f"{m_real['æœ€å¤§å›æ’¤']:.2%}",
                            "å¡ç›æ¯”ç‡": f"{m_real['å¡ç›æ¯”ç‡']:.2f}",
                            "å¤æ™®æ¯”ç‡": f"{m_real['å¤æ™®æ¯”ç‡']:.2f}",
                            "ç´¢æè¯º": f"{m_real['ç´¢æè¯ºæ¯”ç‡']:.2f}",
                            "ä¸Šè¡Œæ•è·": f"{cap_stats['ä¸Šè¡Œæ•è·']:.2%}",
                            "ä¸‹è¡Œæ•è·": f"{cap_stats['ä¸‹è¡Œæ•è·']:.2%}",
                            "èƒœç‡": f"{m_real['æ­£æ”¶ç›Šæ¦‚ç‡(æ—¥)']:.1%}",
                            "CIOç‚¹è¯„": cap_stats['CIOç‚¹è¯„']
                        })
                    if metrics_list:
                        st.dataframe(pd.DataFrame(metrics_list).set_index("äº§å“åç§°"), use_container_width=True)

                    st.markdown("##### 2. æ»šåŠ¨æ•è·ç‡è¶‹åŠ¿ (Rolling Trend)")
                    fig_cap = go.Figure()
                    fig_cap.add_trace(go.Scatter(x=m['Rolling_Up_Cap'].index, y=m['Rolling_Up_Cap'], name="ä¸Šè¡Œæ•è· (è¿›æ”»)", line=dict(color='#1890FF', width=2), fill='tozeroy', fillcolor='rgba(24, 144, 255, 0.1)'))
                    fig_cap.add_trace(go.Scatter(x=m['Rolling_Down_Cap'].index, y=m['Rolling_Down_Cap'], name="ä¸‹è¡Œæ•è· (é˜²å®ˆ)", line=dict(color='#D0021B', width=2), fill='tozeroy', fillcolor='rgba(208, 2, 27, 0.1)'))
                    fig_cap.add_hline(y=1.0, line_dash="dash", line_color="gray", annotation_text="åŸºå‡†æ°´å¹³ (100%)")
                    fig_cap.update_layout(template="plotly_white", height=400, hovermode="x unified", yaxis=dict(title="æ•è·ç‡ (Capture Ratio)", tickformat=".2f"))
                    st.plotly_chart(fig_cap, use_container_width=True)

                # [Dual-Track: Risk/Return Contribution uses Cash Filled]
                # [Fix v7.1.4] Use dynamic frequency factor instead of hardcoded 252
                df_sub_rets = df_attr.pct_change().fillna(0) 
                
                # Detect frequency for risk scaling
                if not df_attr.empty and len(df_attr) > 1:
                    freq_f = get_freq_factor(df_attr.iloc[:,0]) # approximate from first column
                else:
                    freq_f = 252.0
                    
                risk_vals = initial_w_series * (df_sub_rets.std() * np.sqrt(freq_f)) 
                
                contribution_vals = pd.Series(index=df_attr.columns, dtype=float)
                for col in df_attr.columns:
                    s = df_attr[col]
                    if not s.empty: contribution_vals[col] = (s.iloc[-1] / s.iloc[0]) - 1
                    else: contribution_vals[col] = 0.0
                contribution_vals = initial_w_series * contribution_vals

                col_attr1, col_attr2 = st.columns(2)
                col_attr1.plotly_chart(px.pie(names=risk_vals.index, values=risk_vals.values, hole=0.4, title="é£é™©è´¡çŒ®å½’å› ", color=risk_vals.index, color_discrete_map=color_map), use_container_width=True)
                col_attr2.plotly_chart(px.pie(names=contribution_vals.index, values=contribution_vals.abs(), hole=0.4, title="æ”¶ç›Šè´¡çŒ®å½’å› ", color=contribution_vals.index, color_discrete_map=color_map), use_container_width=True)

                st.markdown("---")
                st.markdown("#### åº•å±‚äº§å“èµ°åŠ¿å¯¹æ¯” (ç‹¬ç«‹å½’ä¸€åŒ–)")
                fig_sub_compare = go.Figure()
                # [Dual-Track: Line Chart uses Raw Data for Independent Normalization]
                for col in sel_funds:
                    s_raw = df_db[col].dropna()
                    # Filter to user selected range to keep X-axis consistent
                    s_raw = s_raw.loc[s_raw.index >= df_db.index[0]] 
                    if not s_raw.empty:
                        s_norm = s_raw / s_raw.iloc[0] 
                        fig_sub_compare.add_trace(go.Scatter(x=s_norm.index, y=s_norm, name=col, opacity=0.6, line=dict(color=color_map.get(col))))
                
                if star_nav is not None:
                    fig_sub_compare.add_trace(go.Scatter(x=star_nav.index, y=star_nav, name=star_nav.name, line=dict(color='red', width=4)))
                st.plotly_chart(fig_sub_compare.update_layout(template="plotly_white", height=500), use_container_width=True)
                
                st.plotly_chart(px.imshow(df_sub_rets.corr(), text_auto=".2f", color_continuous_scale=[[0.0, '#1890FF'], [0.5, '#FFFFFF'], [1.0, '#D0021B']], zmin=-1, zmax=1, title="äº§å“ç›¸å…³æ€§çŸ©é˜µ (Pearson)", height=600), use_container_width=True)

        # === Tab 4: é£é™©é£æ´å®éªŒå®¤ (Enhanced v7.2.0) ===
        with tabs[3]:
            if star_nav is not None:
                st.subheader("ğŸŒªï¸ é£é™©é£æ´å®éªŒå®¤ (Risk Lab)")
                
                # [New v7.2.0] Simulation Window Control
                st.markdown("##### 1. è®­ç»ƒæ•°æ®é‡‡æ ·çª—å£ (Training Window)")
                
                sim_options = ["å…¨é‡æ•°æ® (ä¸æ¨è)", "æœ€è¿‘ 5 å¹´", "æœ€è¿‘ 3 å¹´", "æœ€è¿‘ 1 å¹´", "æœ€è¿‘ 6 ä¸ªæœˆ"]
                # é»˜è®¤é€‰æœ€è¿‘ 1 å¹´ï¼Œå› ä¸ºè¿™é€šå¸¸åæ˜ äº†äº§å“å½“å‰çš„çœŸå®ç­–ç•¥ç‰¹å¾
                sim_period = st.select_slider(
                    "è¯·é€‰æ‹©ç”¨äºè®­ç»ƒè’™ç‰¹å¡æ´›æ¨¡å‹çš„æ•°æ®é•¿åº¦ï¼š",
                    options=sim_options,
                    value="æœ€è¿‘ 1 å¹´"
                )
                
                # 1. å‡†å¤‡æ•°æ®: è®¡ç®—ç»„åˆæ—¥æ”¶ç›Šç‡ (Cash Filled)
                star_rets = star_nav.pct_change().dropna()
                
                # [Core Logic] Data Slicing based on Selection
                slice_date = star_rets.index.min()
                if sim_period == "æœ€è¿‘ 5 å¹´":
                    slice_date = star_rets.index.max() - timedelta(days=365*5)
                elif sim_period == "æœ€è¿‘ 3 å¹´":
                    slice_date = star_rets.index.max() - timedelta(days=365*3)
                elif sim_period == "æœ€è¿‘ 1 å¹´":
                    slice_date = star_rets.index.max() - timedelta(days=365)
                elif sim_period == "æœ€è¿‘ 6 ä¸ªæœˆ":
                    slice_date = star_rets.index.max() - timedelta(days=180)
                
                # Apply Slice
                star_rets_trained = star_rets[star_rets.index >= slice_date]
                
                if star_rets_trained.empty:
                    st.error(f"âŒ æ•°æ®ä¸è¶³ï¼šæ‰€é€‰çª—å£å†…æ— æœ‰æ•ˆæ•°æ®ã€‚è¯·é€‰æ‹©æ›´é•¿çš„æ—¶é—´çª—å£ã€‚")
                else:
                    st.caption(f"ğŸ“… å®é™…è®­ç»ƒåŒºé—´: {star_rets_trained.index.min().date()} è‡³ {star_rets_trained.index.max().date()} (æ ·æœ¬æ•°: {len(star_rets_trained)})")
                    
                    # [Fix v7.1.4] æ™ºèƒ½ä¾¦æµ‹æ•°æ®é¢‘ç‡
                    dates_mc = star_rets_trained.index
                    sim_steps = 252 # Default
                    freq_label = "äº¤æ˜“æ—¥"
                    
                    if len(dates_mc) > 1:
                        avg_days = (dates_mc[-1] - dates_mc[0]).days / (len(dates_mc) - 1)
                        if avg_days <= 1.5:
                            sim_steps = 252; freq_label = "äº¤æ˜“æ—¥ (Daily)"
                        elif avg_days <= 8:
                            sim_steps = 52; freq_label = "å‘¨ (Weekly)"
                        elif avg_days <= 35:
                            sim_steps = 12; freq_label = "æœˆ (Monthly)"
                        else:
                            sim_steps = int(365 / avg_days); freq_label = "æœŸ (Periods)"
                    
                    # 2. è¿è¡Œæ¨¡æ‹Ÿ (Monte Carlo)
                    if st.button("ğŸš€ å¯åŠ¨è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿå¼•æ“"):
                        with st.spinner(f"æ­£åœ¨åŸºäº {freq_label} é¢‘ç‡è¿›è¡Œ 1,000 æ¬¡å¹³è¡Œå®‡å®™æ¨æ¼”..."):
                            sim_paths = run_monte_carlo(star_rets_trained, n_sims=1000, n_steps=sim_steps)
                            
                            if sim_paths is not None:
                                # 3. å¯è§†åŒ–: æ‰‡å½¢å›¾ (Fan Chart)
                                p5 = np.percentile(sim_paths, 5, axis=1)
                                p25 = np.percentile(sim_paths, 25, axis=1)
                                p50 = np.percentile(sim_paths, 50, axis=1)
                                p75 = np.percentile(sim_paths, 75, axis=1)
                                p95 = np.percentile(sim_paths, 95, axis=1)
                                
                                x_axis = list(range(len(p50)))
                                
                                fig_mc = go.Figure()
                                # 90% ç½®ä¿¡åŒºé—´
                                fig_mc.add_trace(go.Scatter(x=x_axis, y=p95, mode='lines', line=dict(width=0), showlegend=False, name='95%'))
                                fig_mc.add_trace(go.Scatter(x=x_axis, y=p5, mode='lines', line=dict(width=0), fill='tonexty', fillcolor='rgba(200, 200, 200, 0.2)', name='90% Range'))
                                
                                # 50% ç½®ä¿¡åŒºé—´
                                fig_mc.add_trace(go.Scatter(x=x_axis, y=p75, mode='lines', line=dict(width=0), showlegend=False, name='75%'))
                                fig_mc.add_trace(go.Scatter(x=x_axis, y=p25, mode='lines', line=dict(width=0), fill='tonexty', fillcolor='rgba(100, 100, 255, 0.3)', name='50% Range'))
                                
                                # ä¸­ä½æ•°è·¯å¾„
                                fig_mc.add_trace(go.Scatter(x=x_axis, y=p50, mode='lines', line=dict(color='#1890FF', width=2), name='ä¸­æ€§é¢„æœŸ (Median)'))
                                fig_mc.add_trace(go.Scatter(x=[0], y=[1.0], mode='markers', marker=dict(color='black', size=5), showlegend=False))

                                fig_mc.update_layout(
                                    title=f"æœªæ¥1å¹´è´¢å¯Œè·¯å¾„æ¨æ¼” (Steps={sim_steps})",
                                    xaxis_title=f"æœªæ¥ {freq_label}",
                                    yaxis_title="å‡€å€¼é¢„æœŸ (å½’ä¸€åŒ–)",
                                    template="plotly_white",
                                    height=500
                                )
                                st.plotly_chart(fig_mc, use_container_width=True)
                                
                                # 4. VaR æŒ‡æ ‡è®¡ç®—
                                final_values = sim_paths[-1, :]
                                var_95_val = np.percentile(final_values, 5) - 1
                                var_99_val = np.percentile(final_values, 1) - 1
                                
                                c_var1, c_var2, c_var3 = st.columns(3)
                                c_var1.metric("ä¸­æ€§é¢„æœŸæ”¶ç›Š (Median)", f"{(np.median(final_values)-1):.2%}")
                                c_var2.metric("VaR (95%ç½®ä¿¡åº¦)", f"{var_95_val:.2%}", help="æœ‰5%çš„æ¦‚ç‡ï¼Œæœªæ¥ä¸€å¹´äºæŸè¶…è¿‡æ­¤æ•°å€¼")
                                c_var3.metric("VaR (99%ç½®ä¿¡åº¦)", f"{var_99_val:.2%}", help="æœ‰1%çš„æ¦‚ç‡ï¼Œæœªæ¥ä¸€å¹´äºæŸè¶…è¿‡æ­¤æ•°å€¼")
                                
                                if var_95_val < -0.2:
                                    st.error(f"âš ï¸ **é£æ§é¢„è­¦**ï¼šæç«¯æƒ…å†µä¸‹ (95% VaR)ï¼Œç»„åˆå¯èƒ½é¢ä¸´ **{abs(var_95_val):.1%}** çš„å›æ’¤é£é™©ï¼Œè¯·æ£€æŸ¥æ æ†æˆ–é«˜æ³¢èµ„äº§æƒé‡ã€‚")
                                else:
                                    st.success(f"âœ… **é£æ§è¯„ä¼°**ï¼šåœ¨ 95% ç½®ä¿¡åº¦ä¸‹ï¼Œæœªæ¥ä¸€å¹´æ½œåœ¨æœ€å¤§äºæŸæ§åˆ¶åœ¨ **{abs(var_95_val):.1%}** ä»¥å†…ï¼Œå±äºç¨³å¥åŒºé—´ã€‚")

            else: st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§åŠ è½½ç»„åˆä»¥å¯åŠ¨å®éªŒå®¤ã€‚")

    else: st.info("ğŸ‘‹ è¯·ä¸Šä¼ â€˜äº§å“æ•°æ®åº“â€™ä»¥å¯åŠ¨å¼•æ“ã€‚")
